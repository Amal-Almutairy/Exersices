---
title: "Boston housing - LR"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Helper packages
library(dplyr)    # for data manipulation
library(ggplot2)  # for awesome graphics

# Modeling packages
library(caret)    # for cross-validation, etc.
library(rsample)  # for sampling

library(caret)
library(mlbench)


data(BostonHousing)
head(BostonHousing)

install.packages("pdp")
```

```{r}
library(MASS)
library(ISLR)

```

## Exercises
Using the Boston housing data set from the pdp package, where the response feature is the median value of homes within a census tract (cmedv):

```{r}
head(BostonHousing)
summary(BostonHousing)
str(BostonHousing)
```
# 1
Pick a single feature and apply simple linear regression model.
Interpret the feature’s coefficient
What is the model’s performance? How does it compare to the KNN in the last module?

```{r pressure, echo=FALSE}
# EDA

dim(BostonHousing)

#SLR
b_model <- lm(indus ~ crime, data = BostonHousing)
summary(b_model)

# RMSE
sigma(b_model)

# MSE
sigma(b_model)^2


```
## 2
Pick another feature to add to the model.
Before applying the module why do you think this feature will help?

Apply a linear regression model with the two features and compare to the simple linear model.
Interpret the coefficients.
```{r}
# EDA

dim(BostonHousing)

#SLR
b_model2 <- lm(tax ~ medv, data = BostonHousing)
summary(b_model2)

# RMSE
sigma(b_model2)

# MSE
sigma(b_model2)^2


# check missing value
sum(is.na(BostonHousing))


```

## 3
Now apply a model that includes all the predictors.
How does this model compare to the previous two?
Can you identify any model concerns?

```{r}
#SLR
b_model3 <- lm(tax + indus ~ medv, data = BostonHousing)
summary(b_model3)
b_model3


# check missing value
sum(is.na(BostonHousing))

# To achieve reproducible model; set the random seed number
set.seed(100)
# Performs stratified random split of the data set
TrainingIndex <- createDataPartition(BostonHousing$medv, p=0.8, list = FALSE)
TrainingSet <- BostonHousing[TrainingIndex,] # Training Set
TestingSet <- BostonHousing[-TrainingIndex,] # Test Set

dim(TrainingSet)
dim(TestingSet)
TrainingIndex

# Build Training model
Model <- train(medv ~ ., data = TrainingSet,
               method = "lm",
               na.action = na.omit,
               preProcess=c("scale","center"),
               trControl= trainControl(method="none")
)
Model
# Apply model for prediction
Model.training <-predict(Model, TrainingSet) # Apply model to make prediction on Training set
Model.testing <-predict(Model, TestingSet) # Apply model to make prediction on Testing set
# Model performance
# Scatter plot of Training set
plot(TrainingSet$medv,Model.training, col = "blue" )
plot(TestingSet$medv,Model.testing, col = "blue" )

Model.training <- predict(Model, Trainingset)
Model.testing <- predict(Model, Trainingset)
Model.training
Model.testing
```

## 5
Apply a principal component regression model.
Perform a grid search over several components.
Identify and explain the performance of the optimal model.
```{r}

```

## 6
Now apply a partial least square model.
Perform a grid search over several components.
Identify and explain the performance of the optimal model.
Python challenge: Repeat the above exercises but using Python and Scikit Learn. Recall that Scikit Learn provides the boston housing data set.




```{r}
predict(fit1,data.frame(lstat=c(10,20,30)),interval="confidence")
```


```{r}
data.frame(lstat=c(10,20,30))
par(mfrow=c(2,2))
plot(fit1)
```

```{r}
fit2=lm(medv~lstat+age,data=Boston)
summary(fit2)

```

```{r}
fit3=lm(medv~.,Boston)
summary(fit3)

par(mfrow=c(2,2))
plot(fit3)
```
```{r}
fit4=update(fit3,~.-age-indus)
summary(fit4)
```
```{r}
fit6=lm(medv~lstat +I(lstat^2),Boston)
summary(fit6)

```
```{r}
attach(Boston)
par(mfrow=c(1,1))
plot(medv~lstat, Boston)
points(lstat,fitted(fit6), col="red",pch=20)
```
```{r}
fit7=lm(medv~poly(lstat,4))
plot(medv~lstat)
points(lstat,fitted(fit7),col="blue",pch=20)

```

```{r}
fit5=lm(medv~lstat*age,Boston)
summary(fit5)
```

```{r}
fit6=lm(medv~lstat+crim+rm+dis+black+chas+nox+rad+tax+ptratio+I(lstat^2)+I(rm^2))
summary(fit6)
```
```{r}
par(mfrow=c(2,2))
plot(fit6)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
